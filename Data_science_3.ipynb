{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6e89GvMYXxtsU6rkQV4oa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RosaGaLl/Data-Science_Machine-Learning/blob/main/Data_science_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MNIST digits classification dataset**\n"
      ],
      "metadata": {
        "id": "bFn0say4E69h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Descripción del problema de negocio**"
      ],
      "metadata": {
        "id": "od3YvCYvFssf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El presente dataset recopila las opiniones de los usuarios sobre películas, las cuales pueden influir considerablemente en las decisiones de otros usuarios al momento de elegir una película nueva.Puesto que, si ahondamos más en estas reseñas podemos deducir que contienen valiosos sentimientos que reflejan la opinión de los espectadores.\n",
        "\n",
        "Considerando ello, el contar con un sistema automático de análisis de sentimientos puede ayudar a plataformas de streaming, productoras o sitios de críticas a conocer la percepción general del público ante las películas vistas. Asimismo, el poder analizar estos textos y clasificarlos como positivos o negativos permite a estas mismas empresas entender mejor la recepción de los productos cinematográficos que se ofrecen, incluse se podrían ajustar estrategias de marketing o incluso ayudar a sus sistemas de recomendación."
      ],
      "metadata": {
        "id": "accLn6F_kQcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Objetivo general**"
      ],
      "metadata": {
        "id": "0WVSEikoYzUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo general de este proyecto es poder construir y mejorar\n",
        "una red neuronal profunda que permita clasificar automáticamente las reseñas de películas como positivas o negativas, utilizando el dataset.\n",
        "Y para ello, se usarán técnicas de Deep Learning aplicadas a Procesamiento de Lenguaje Natural (NLP), lo que permitirá que sea posible poder automatizar los análisis de los comentarios de las películas."
      ],
      "metadata": {
        "id": "1w8yGRC4owpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.Origen de los datos**"
      ],
      "metadata": {
        "id": "MPMp_oJCoZud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset a usar se encuentra disponible directamente en Keras a través del módulo keras.datasets.imdb.\n",
        "Este contiene 25.000 reseñas de entrenamiento y 25.000 de prueba, etiquetadas como positivas = 1 o negativas =0. Las reseñas ya están preprocesadas y tokenizadas como secuencias de índices de palabras, lo cual nos permite obtener un análisis más detallado."
      ],
      "metadata": {
        "id": "2VJuijBCoZk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Definición de las variables**\n"
      ],
      "metadata": {
        "id": "UnNsqrdjo2WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   x_train, x_test: Listas de secuencias de enteros, donde cada entero representa una palabra\n",
        "*   y_train, y_test: Listas de etiquetas binarias las cuales son: 0 = negativo y 1 = positivo\n",
        "*   num_words: Número de palabras más frecuentes que se conservarán en el vocabulario.\n",
        "*   Longitud de las secuencias: Se da a conocer un maxlen para uniformar la longitud de entrada.\n",
        "*  Las reseñas se encuentran tokenizadas\n",
        "\n"
      ],
      "metadata": {
        "id": "rHHQL-dgo-AJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.Librerías a usar en el proyecto**"
      ],
      "metadata": {
        "id": "L1V9Dh6LY-tK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalación de Librerías"
      ],
      "metadata": {
        "id": "b3I0WHc-vmdx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NAWQ6LqKjaBV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Conv1D, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.Desarrollo**"
      ],
      "metadata": {
        "id": "5qCcHgdApVrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a) Carga del dataset**"
      ],
      "metadata": {
        "id": "TB-c90hFrB6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se carga el dataset con solo las 10000 palabras más frecuentes para tener un análisis más profundo y detallado\n",
        "num_words = 10000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
        "\n",
        "\n",
        "# Es la longitud máxima de secuencia de las reseñas que se tienen\n",
        "maxlen = 200\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n"
      ],
      "metadata": {
        "id": "6HK1vDbPrNKO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b) Análisis exploratorio + insights**"
      ],
      "metadata": {
        "id": "V2vA9sStrRui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Número de reseñas de entrenamiento: {len(x_train)}\")\n",
        "print(f\"Número de reseñas de prueba: {len(x_test)}\")\n",
        "print(f\"Longitud media de las reseñas: {np.mean([len(x) for x in x_train]):.2f}\")\n",
        "print(f\"Distribución de clases en entrenamiento: {np.unique(y_train, return_counts=True)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIx88MAcrQB0",
        "outputId": "8f332f17-7645-4693-c8b9-fa701d783a5a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de reseñas de entrenamiento: 25000\n",
            "Número de reseñas de prueba: 25000\n",
            "Longitud media de las reseñas: 200.00\n",
            "Distribución de clases en entrenamiento: (array([0, 1]), array([12500, 12500]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De los insights se tiene que:\n",
        "\n",
        "Las clases están balanceadas: 50% positivas, 50% negativas.\n",
        "\n",
        "Las reseñas tienen longitudes variadas, de ahí la necesidad de pad_sequences.\n",
        "\n",
        "Solo las 10.000 palabras más frecuentes se usan para reducir complejidad."
      ],
      "metadata": {
        "id": "v2-fayNsrZHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c) Red neuronal sencilla**"
      ],
      "metadata": {
        "id": "AJkWRSoJriMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=num_words, output_dim=64, input_length=maxlen),\n",
        "    LSTM(64),  # capa recurrente\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE3-PllbrP6m",
        "outputId": "f705f010-2f73-4998-8dcf-b094effe1005"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 151ms/step - accuracy: 0.6869 - loss: 0.5729 - val_accuracy: 0.8714 - val_loss: 0.3167\n",
            "Epoch 2/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 138ms/step - accuracy: 0.9002 - loss: 0.2555 - val_accuracy: 0.8702 - val_loss: 0.3144\n",
            "Epoch 3/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 147ms/step - accuracy: 0.9318 - loss: 0.1849 - val_accuracy: 0.8710 - val_loss: 0.3289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d) Evaluación**"
      ],
      "metadata": {
        "id": "wUU6pDp_rmCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(x_test, y_test)\n",
        "print(f\"Precisión en test: {results[1]*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zR_0NtprPy-",
        "outputId": "0bce9804-0594-41ef-eacb-6d9879a4a65f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.8647 - loss: 0.3410\n",
            "Precisión en test: 86.66%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. Profundización en Deep Learning (Mejora del modelo)**"
      ],
      "metadata": {
        "id": "-heoKF4Hs3_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Desde aquí se define la arquitectura del modelo con capas adicionales, se usa la capa convolucional para captar patrones locales,capa densa y la capa de salida binaria\n",
        "model_dl = Sequential([\n",
        "    Embedding(input_dim=num_words, output_dim=64, input_length=maxlen),\n",
        "    Conv1D(64, 5, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "# Se compila el modelo\n",
        "model_dl.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Se procede seguidamente a entrenar la red\n",
        "history_dl = model_dl.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-xcmX-RtIHG",
        "outputId": "591c3591-94db-4cff-f1e7-d073e75fae06"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 180ms/step - accuracy: 0.6531 - loss: 0.5864 - val_accuracy: 0.8658 - val_loss: 0.3518\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 187ms/step - accuracy: 0.8986 - loss: 0.2771 - val_accuracy: 0.8652 - val_loss: 0.3263\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 182ms/step - accuracy: 0.9337 - loss: 0.1911 - val_accuracy: 0.8780 - val_loss: 0.2987\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 188ms/step - accuracy: 0.9607 - loss: 0.1256 - val_accuracy: 0.8750 - val_loss: 0.3665\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 193ms/step - accuracy: 0.9703 - loss: 0.0939 - val_accuracy: 0.8718 - val_loss: 0.3806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Comparación de resultados***"
      ],
      "metadata": {
        "id": "vXWqFs7Zr_Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_base, acc_base = model.evaluate(x_test, y_test)\n",
        "loss_dl, acc_dl = model_dl.evaluate(x_test, y_test)\n",
        "\n",
        "print(f\"Modelo sencillo - Precisión: {acc_base*100:.2f}%\")\n",
        "print(f\"Modelo mejorado - Precisión: {acc_dl*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW2NHLIMzhwr",
        "outputId": "f6e6c246-27c5-4eb7-960b-11b3ef21f6ea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.8647 - loss: 0.3410\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.8528 - loss: 0.4880\n",
            "Modelo sencillo - Precisión: 86.66%\n",
            "Modelo mejorado - Precisión: 85.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "12GXliiwr_WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j8B_0X7Fr_TP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i_KVKCS2r_M-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LKBDlRS0r_JX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YVk55sEIr_Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar solo las 10,000 palabras más frecuentes\n",
        "num_words = 10000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpkx03Zhvk4v",
        "outputId": "5383bef2-f0fe-4f98-f7a9-075aec82ba14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zOpFPX_Cuqr",
        "outputId": "bb9e1e50-7e25-4302-8662-f315eedfb8d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test shape: (25000, 200)\n",
            "y_test shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se da el preprocesamiento ( Rellenado de reseñas para que tengan la misma longitud)"
      ],
      "metadata": {
        "id": "ZsJKI4jAwjNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 200  # Cortamos o rellenamos a 200 palabras por reseña\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n"
      ],
      "metadata": {
        "id": "irXm1_A7wstI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploración del dataset"
      ],
      "metadata": {
        "id": "I2Ds-ix5xarS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Número de reseñas de entrenamiento: {len(x_train)}\")\n",
        "print(f\"Ejemplo de reseña (como secuencia de índices):\\n{x_train[0]}\")\n",
        "print(f\"Etiqueta (0=negativa, 1=positiva): {y_train[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggow9Gg3xZuh",
        "outputId": "b789b17e-704c-40d2-e612-9c20797f833b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de reseñas de entrenamiento: 25000\n",
            "Ejemplo de reseña (como secuencia de índices):\n",
            "[   5   25  100   43  838  112   50  670    2    9   35  480  284    5\n",
            "  150    4  172  112  167    2  336  385   39    4  172 4536 1111   17\n",
            "  546   38   13  447    4  192   50   16    6  147 2025   19   14   22\n",
            "    4 1920 4613  469    4   22   71   87   12   16   43  530   38   76\n",
            "   15   13 1247    4   22   17  515   17   12   16  626   18    2    5\n",
            "   62  386   12    8  316    8  106    5    4 2223 5244   16  480   66\n",
            " 3785   33    4  130   12   16   38  619    5   25  124   51   36  135\n",
            "   48   25 1415   33    6   22   12  215   28   77   52    5   14  407\n",
            "   16   82    2    8    4  107  117 5952   15  256    4    2    7 3766\n",
            "    5  723   36   71   43  530  476   26  400  317   46    7    4    2\n",
            " 1029   13  104   88    4  381   15  297   98   32 2071   56   26  141\n",
            "    6  194 7486   18    4  226   22   21  134  476   26  480    5  144\n",
            "   30 5535   18   51   36   28  224   92   25  104    4  226   65   16\n",
            "   38 1334   88   12   16  283    5   16 4472  113  103   32   15   16\n",
            " 5345   19  178   32]\n",
            "Etiqueta (0=negativa, 1=positiva): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decodificar una reseña para ver el texto"
      ],
      "metadata": {
        "id": "JUqXCK4-BxHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar diccionario de palabras\n",
        "word_index = imdb.get_word_index()\n",
        "index_from = 3\n",
        "word_index = {k:(v+index_from) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<OOV>\"] = 2\n",
        "\n",
        "# Invertir el diccionario\n",
        "reverse_index = {v:k for k,v in word_index.items()}\n",
        "\n",
        "# Decodificar\n",
        "decoded_review = ' '.join([reverse_index.get(i, \"?\") for i in x_train[0]])\n",
        "print(decoded_review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uxL4-uIB2pl",
        "outputId": "b3c608f4-15ca-4175-cb86-6027a266ed10"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "and you could just imagine being there robert <OOV> is an amazing actor and now the same being director <OOV> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <OOV> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <OOV> to the two little boy's that played the <OOV> of norman and paul they were just brilliant children are often left out of the <OOV> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Armar una red neuronal sencilla (con embedding)"
      ],
      "metadata": {
        "id": "VX_LHInIBxE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(input_dim=num_words, output_dim=32, input_length=maxlen),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(16, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')  # Salida binaria\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "MehsU8B7CBNm",
        "outputId": "b005503a-424b-4c91-dfe8-a01e92a960c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenar el modelo"
      ],
      "metadata": {
        "id": "TEqh9uDnBxCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=5, batch_size=512, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCh8z4WECMne",
        "outputId": "e01f94e4-d1e6-4ed9-849d-3ea20121a5e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.1026 - loss: -156.1726 - val_accuracy: 0.1018 - val_loss: -2414.8191\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.0998 - loss: -5093.9731 - val_accuracy: 0.1018 - val_loss: -18252.2148\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.1026 - loss: -27138.1074 - val_accuracy: 0.1018 - val_loss: -61530.9766\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.1013 - loss: -80740.0625 - val_accuracy: 0.1018 - val_loss: -145875.4531\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.1041 - loss: -182274.5312 - val_accuracy: 0.1018 - val_loss: -282935.6562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluar y graficar resultados"
      ],
      "metadata": {
        "id": "Ov7RTULKCSgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(x_test, y_test)\n",
        "print(f\"Precisión en test: {results[1]*100:.2f}%\")\n",
        "\n",
        "# Graficar entrenamiento\n",
        "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
        "plt.plot(history.history['val_accuracy'], label='Validación')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Precisión\")\n",
        "plt.title(\"Evolución de la precisión\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ffoBDbBACTcU",
        "outputId": "2dadc313-c719-4f38-8df5-b9946aed0776"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 25000\n'y' sizes: 10000\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-60f852b3d7ce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Precisión en test: {results[1]*100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Graficar entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Entrenamiento'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/data_adapter_utils.py\u001b[0m in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    113\u001b[0m             )\n\u001b[1;32m    114\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"'{label}' sizes: {sizes}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 25000\n'y' sizes: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rFgnos91BxAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P7pZKDjKBw-W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SYpFTBk6Bw5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1IENiZQqBw3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0ld9wtQBw0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I5mlfK-zBwy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oh-3mdYMBwwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-IGMNBsXBwuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eHuUs3_HBwsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZJ0GuY3IBwpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ciybRTJ4BwnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rQmJvnv_BwlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pb0al4ZEBwiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MbwrAh9awe2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar diccionario de palabras\n",
        "word_index = imdb.get_word_index()\n",
        "index_from = 3\n",
        "word_index = {k:(v+index_from) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<OOV>\"] = 2\n",
        "\n",
        "# Invertir el diccionario\n",
        "reverse_index = {v:k for k,v in word_index.items()}\n",
        "\n",
        "# Decodificar\n",
        "decoded_review = ' '.join([reverse_index.get(i, \"?\") for i in x_train[0]])\n",
        "print(decoded_review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzvmgbNOxfu4",
        "outputId": "b386274b-9a69-46fc-e484-ce0edf442479"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "and you could just imagine being there robert <OOV> is an amazing actor and now the same being director <OOV> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <OOV> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <OOV> to the two little boy's that played the <OOV> of norman and paul they were just brilliant children are often left out of the <OOV> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decodificar una reseña para ver el texto"
      ],
      "metadata": {
        "id": "JrfsvGRUwet2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Cargar datos\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n"
      ],
      "metadata": {
        "id": "reZ0a8l1jg7q"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}